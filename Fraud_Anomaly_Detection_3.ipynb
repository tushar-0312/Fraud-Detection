{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CREDIT CARD FRAUD ANALYSIS\n",
    "\n",
    "## PART 3 : Anomaly Detection Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anomaly Detection**\n",
    "\n",
    "Anomaly detection is a technique used to identify unusual patterns that do not conform to expected behavior, called outliers. It has many applications in business, from intrusion detection (identifying strange patterns in network traffic that could signal a hack) to system health monitoring (spotting a malignant tumor in an MRI scan), and from fraud detection in credit card transactions to fault detection in operating environments.\n",
    "\n",
    "\n",
    "What Are Anomalies?\n",
    "Anomalies can be broadly categorized as:\n",
    "\n",
    "- Point anomalies:\n",
    "A single instance of data is anomalous if it's too far off from the rest. Business use case: Detecting credit card fraud based on \"amount spent.\"\n",
    "\n",
    "- Contextual anomalies:\n",
    "The abnormality is context specific. This type of anomaly is common in time-series data. Business use case: Spending $100 on food every day during the holiday season is normal, but may be odd otherwise.\n",
    "\n",
    "- Collective anomalies:\n",
    "A set of data instances collectively helps in detecting anomalies. Business use case: Someone is trying to copy data form a remote machine to a local host unexpectedly, an anomaly that would be flagged as a potential cyber attack.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection Techniques\n",
    "\n",
    "**Simple Statistical Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The simplest approach to identifying irregularities in data is to flag the data points that deviate from common statistical properties of a distribution, including mean, median, mode, and quantiles. Let's say the definition of an anomalous data point is one that deviates by a certain standard deviation from the mean. Traversing mean over time-series data isn't exactly trivial, as it's not static. You would need a rolling window to compute the average across the data points. Technically, this is called a rolling average or a moving average, and it's intended to smooth short-term fluctuations and highlight long-term ones. Mathematically, an n-period simple moving average can also be defined as a \"low pass filter.\"\n",
    "\n",
    "**Challenges with Simple Statistical Methods**\n",
    "The low pass filter allows you to identify anomalies in simple use cases, but there are certain situations where this technique won't work. Here are a few:\n",
    "\n",
    "The data contains noise which might be similar to abnormal behavior, because the boundary between normal and abnormal behavior is often not precise.\n",
    "\n",
    "The definition of abnormal or normal may frequently change, as malicious adversaries constantly adapt themselves. Therefore, the threshold based on moving average may not always apply.\n",
    "\n",
    "The pattern is based on seasonality. This involves more sophisticated methods, such as decomposing the data into multiple trends in order to identify the change in seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning based Approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Density-Based Anomaly Detection**\n",
    "Density-based anomaly detection is based on the k-nearest neighbors algorithm.\n",
    "Assumption: Normal data points occur around a dense neighborhood and abnormalities are far away. The nearest set of data points are evaluated using a score, which could be Eucledian distance or a similar measure dependent on the type of the data (categorical or numerical). They could be broadly classified into two algorithms:\n",
    "\n",
    "  - **K-nearest neighbor:**\n",
    "k-NN is a simple, non-parametric lazy learning technique used to classify data based on similarities in distance metrics such as Eucledian, Manhattan, Minkowski, or Hamming distance.\n",
    "\n",
    "  - **Relative density of data:**\n",
    "This is better known as local outlier factor (LOF). This concept is based on a distance metric called reachability distance.\n",
    "\n",
    "\n",
    "- **Clustering-Based Anomaly Detection**\n",
    "Clustering is one of the most popular concepts in the domain of unsupervised learning.\n",
    "Assumption: Data points that are similar tend to belong to similar groups or clusters, as determined by their distance from local centroids. K-means is a widely used clustering algorithm. It creates 'k' similar clusters of data points. Data instances that fall outside of these groups could potentially be marked as anomalies.\n",
    "\n",
    "- **Support Vector Machine-Based Anomaly Detection**\n",
    "A support vector machine is another effective technique for detecting anomalies.\n",
    "A SVM is typically associated with supervised learning, but there are extensions (OneClassCVM, for instance) that can be used to identify anomalies as an unsupervised problems (in which training data are not labeled). The algorithm learns a soft boundary in order to cluster the normal data instances using the training set, and then, using the testing instance, it tunes itself to identify the abnormalities that fall outside the learned region.\n",
    "Depending on the use case, the output of an anomaly detector could be numeric scalar values for filtering on domain-specific thresholds or textual labels (such as binary/multi labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement \n",
    "\n",
    "\n",
    "The Credit Card Fraud Detection Problem includes modeling past credit card transactions with the knowledge of the ones that turned out to be fraud. This model is then used to identify whether a new transaction is fraudulent or not. Our aim here is to detect 100 %\n",
    "of the fraudulent transactions while minimizing the incorrect fraud classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches \n",
    "\n",
    "- Isolation Forest Anomaly Detection Algorithm\n",
    "- Density-Based Anomaly Detection (Local Outlier Factor)Algorithm\n",
    "- Support Vector Machine Anomaly Detection Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Isolation Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFERENCES\n",
    "\n",
    "\n",
    "[1] https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e\n",
    "\n",
    "[2] https://heartbeat.fritz.ai/isolation-forest-algorithm-for-anomaly-detection-2a4abd347a5\n",
    "\n",
    "[3] https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the Isolation Forest**\n",
    "\n",
    "Isolation Forest, like any tree ensemble method, is built on the basis of decision trees. In these trees, partitions are created by first randomly selecting a feature and then selecting a random split value between the minimum and maximum value of the selected feature.\n",
    "In principle, outliers are less frequent than regular observations and are different from them in terms of values (they lie further away from the regular observations in the feature space). That is why by using such random partitioning they should be identified closer to the root of the tree (shorter average path length, i.e., the number of edges an observation must pass in the tree going from the root to the terminal node), with fewer splits necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anomaly Score computation in Isolation forest**\n",
    "\n",
    "As with other outlier detection methods, an anomaly score is required for decision making. In the case of Isolation Forest, it is defined as:\n",
    "\n",
    "$$\n",
    "\\\\s(x,n) = 2^\\frac{-E(h(x)}{c(n)}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "- $\\\\h(x)$ is the path length of the observation $\\\\x$ \n",
    "\n",
    "- $\\\\c(n)$ is average path length of unsuccessful search in a binary tree$\\\\x$\n",
    "\n",
    "- $\\\\n$ is the number of external nodes \n",
    "\n",
    "also $\\\\c(n)$ is given as follows \n",
    "\n",
    "$$\n",
    "\\\\c(n) = 2H(n-1) - (2(n-1)/n)  \n",
    "$$\n",
    "\n",
    "where $\\\\H(i)$ is the harmonic number and it can be estimated by $\\\\ln(i) + 0.5772156649 $ (Euler’s constant)\n",
    "\n",
    "\n",
    "- A score close to 1 indicates anomalies\n",
    "- Score much smaller than 0.5 indicates normal observations\n",
    "- If all scores are close to 0.5 then the entire sample does not seem to have clearly distinct anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Local Outlier Factor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFERENCES \n",
    "\n",
    "[4] https://towardsdatascience.com/local-outlier-factor-lof-algorithm-for-outlier-identification-8efb887d9843\n",
    "\n",
    "[5] https://towardsdatascience.com/local-outlier-factor-for-anomaly-detection-cc0c770d2ebe\n",
    "\n",
    "[6] https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the LOF method?**\n",
    "\n",
    "When a point is considered as an outlier based on its local neighborhood, it is a local outlier. LOF will identify an outlier considering the density of the neighborhood. LOF performs well when the density of the data is not the same throughout the dataset.\n",
    "To understand LOF, we have to learn a few concepts sequentially:\n",
    "\n",
    "- K-distance and K-neighbors\n",
    "- Reachability distance (RD)\n",
    "- Local reachability density (LRD)\n",
    "- Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **K Distance and K Neighbours**\n",
    "\n",
    "    K-distance is the distance between the point, and it’s Kᵗʰ nearest neighbor. K-neighbors denoted by Nₖ(A) includes a set of points that lie in or on the circle of radius K-distance. K-neighbors can be more than or equal to the value of K. \n",
    "    \n",
    "- **Reachability distance (RD)**\n",
    "\n",
    "    It is defined as the maximum of K-distance of Xj and the distance between Xi and Xj. The distance measure is problem-specific (Euclidean, Manhattan, etc.)\n",
    "\n",
    "    In layman terms, if a point Xi lies within the K-neighbors of Xj, the reachability distance will be K-distance of Xj , else reachability distance will be the distance between Xi and Xj. Thus mathematicallywe have the following: \n",
    "    \n",
    "$$\n",
    "RD(X_{i},X_{j}) = max(K-Distance(X_{j}), distance(X_{i},X_{j}))\n",
    "$$\n",
    "\n",
    "\n",
    "- **Local Reachability Density** \n",
    "\n",
    "    LRD is inverse of the average reachability distance of A from its neighbors. Intuitively according to LRD formula, more the average reachability distance (i.e., neighbors are far from the point), less density of points are present around a particular point. This tells how far a point is from the nearest cluster of points. Low values of LRD implies that the closest cluster is far from the point.\n",
    "    \n",
    "$$\n",
    "LRD_K(A) = \\frac{1}{\\sum_{X_{j} \\in N_k(A)} \\frac{RD(A,X_{j})}{\\lVert N_k(A) \\rVert}}\n",
    "$$\n",
    "\n",
    "\n",
    "- **LOCAL OUTLIER FACTOR** \n",
    "\n",
    "    RD of each point is used to compare with the average LRD of its K neighbors. LOF is the ratio of the average LRD of the K neighbors of A to the LRD of A.\n",
    "    \n",
    "    Intuitively, if the point is not an outlier (inlier), the ratio of average LRD of neighbors is approximately equal to the LRD of a point (because the density of a point and its neighbors are roughly equal). In that case, LOF is nearly equal to 1. On the other hand, if the point is an outlier, the LRD of a point is less than the average LRD of neighbors. Then LOF value will be high.\n",
    "    \n",
    "    Generally, if LOF> 1, it is considered as an outlier, but that is not always true. Let’s say we know that we only have one outlier in the data, then we take the maximum LOF value among all the LOF values, and the point corresponding to the maximum LOF value will be considered as an outlier.\n",
    "    \n",
    "$$\n",
    "LOF_K(A) = \\frac{\\sum_{X_{j} \\in N_k(A)} LRD_k(X_{j}) }{\\lVert N_k(A) \\rVert} \\times \\frac{1}{ LRD_k(A)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. One Class SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  REFERENCES\n",
    "\n",
    "[7] https://towardsdatascience.com/support-vector-machine-svm-for-anomaly-detection-73a8d676c331\n",
    "\n",
    "\n",
    "[8]http://rvlasveld.github.io/blog/2013/07/12/introduction-to-one-class-support-vector-machines/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECAP of Two Class SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first take a look at the traditional two-class support vector machine. Consider a data set Ω={(x1,y1),(x2,y2),…,(xn,yn)}; points xi∈ℝd in a (for instance two-dimensional) space where xi is the i-th input data point and yi∈{−1,1} is the i-th output pattern, indicating the class membership.\n",
    "\n",
    "A very nice property of SVMs is that it can create a non-linear decision boundary by projecting the data through a non-linear function ϕ to a space with a higher dimension. This means that data points which can’t be separated by a straight line in their original space I are “lifted” to a feature space F where there can be a “straight” hyperplane that separates the data points of one class from an other. \n",
    "\n",
    "The hyperplane is represented with the equation wTx+b=0, with w∈F and b∈R. The hyperplane that is constructed determines the margin between the classes; all the data points for the class −1 are on one side, and all the data points for class 1 on the other. The distance from the closest point from each class to the hyperplane is equal; thus the constructed hyperplane searches for the maximal margin (“separating power”) between the classes. To prevent the SVM classifier from over-fitting with noisy data (or to create a soft margin), slack variables ξi are introduced to allow some data points to lie within the margin, and the constant C>0 determines the trade-off between maximizing the margin and the number of training data points within that margin (and thus training errors). The objective function of the SVM classifier is the following minimization formulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{w,b,\\xi} \\quad & \\frac{1}{2}w^{t}w+C\\sum_{i=1}^{N}{\\xi_{i}}\\\\\n",
    "\\textrm{s.t.} \\quad & y_{i}(w\\phi(x_{i}+b)) \\geq 1-  \\xi_{i} \\;  \\textrm{for all i= 1,...,n} \\\\\n",
    "  &\\xi\\geq0  \\;  \\textrm{for all i= 1,...,n}  \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Class SVM according to Schölkopf\n",
    "\n",
    "**REFERENCE**\n",
    "[9] http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.575&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Support Vector Method For Novelty Detection by Schölkopf et al. basically separates all the data points from the origin (in feature space F) and maximizes the distance from this hyperplane to the origin. This results in a binary function which captures regions in the input space where the probability density of the data lives. Thus the function returns +1 in a “small” region (capturing the training data points) and −1 elsewhere.\n",
    "\n",
    "The quadratic programming minimization function is slightly different from the original stated above, but the similarity is still clear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{w,b,\\xi} \\quad & \\frac{1}{2}w^{t}w+ \\frac{1}{v\\nu}\\sum_{i=1}^{N}{\\xi_{i} - \\rho}\\\\\n",
    "\\textrm{s.t.} \\quad & y_{i}(w\\phi(x_{i})) \\geq \\rho -  \\xi_{i} \\;  \\textrm{for all i= 1,...,n} \\\\\n",
    "  &\\xi\\geq0  \\;  \\textrm{for all i= 1,...,n}  \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous formulation the parameter C decided the smoothness. In this formula it is the parameter $\\nu$ that characterizes the solution;\n",
    "\n",
    "it sets an upper bound on the fraction of outliers (training examples regarded out-of-class) and,\n",
    "it is a lower bound on the number of training examples used as Support Vector.\n",
    "Due to the importance of this parameter, this approach is often referred to as $\\nu$-SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE IMPLEMENTATION \n",
    "\n",
    "**REFERENCE**\n",
    "[10]. https://www.kaggle.com/naveengowda16/anomaly-detection-credit-card-fraud-analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Determine the number of fraud and valid transactions in the entire dataset\n",
    "\n",
    "count_classes = pd.value_counts(data['Class'], sort = True)\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction Class Distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning the transaction class \"0 = NORMAL  & 1 = FRAUD\"\n",
    "Normal = data[data['Class']==0]\n",
    "Fraud = data[data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017304810878113635\n",
      "Fraud Cases : 492\n",
      "Valid Cases : 284314\n"
     ]
    }
   ],
   "source": [
    "### Print outlier fraction \n",
    "\n",
    "Fraud = data[data['Class']==1]\n",
    "Valid = data[data['Class']==0]\n",
    "outlier_fraction = len(Fraud)/float(len(Valid))\n",
    "\n",
    "print(outlier_fraction)\n",
    "print(\"Fraud Cases : {}\".format(len(Fraud)))\n",
    "print(\"Valid Cases : {}\".format(len(Valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset data**\n",
    "\n",
    "We choose a $ 10\\%$ fraction of the orginal data set and build models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016529506928325245\n",
      "Fraud Cases : 47\n",
      "Valid Cases : 28434\n"
     ]
    }
   ],
   "source": [
    "data1= data.sample(frac = 0.1,random_state=1)\n",
    "\n",
    "Fraud1 = data1[data1['Class']==1]\n",
    "Valid1 = data1[data1['Class']==0]\n",
    "outlier_fraction1 = len(Fraud1)/float(len(Valid1))\n",
    "\n",
    "print(outlier_fraction1)\n",
    "print(\"Fraud Cases : {}\".format(len(Fraud1)))\n",
    "print(\"Valid Cases : {}\".format(len(Valid1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELLING\n",
    "\n",
    "**Prepare X, Y Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28481, 30)\n",
      "(28481,)\n"
     ]
    }
   ],
   "source": [
    "#Get all the columns from the dataframe\n",
    "\n",
    "columns = data1.columns.tolist()\n",
    "# Filter the columns to remove data we do not want \n",
    "columns = [c for c in columns if c not in [\"Class\"]]\n",
    "# Store the variable we are predicting \n",
    "target = \"Class\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "X = data1[columns]\n",
    "Y = data1[target]\n",
    "X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n",
    "# Print the shapes of X & Y\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the outlier detection methods\n",
    "\n",
    "classifiers = {\n",
    "    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X), \n",
    "                                       contamination=outlier_fraction,random_state=state, verbose=0),\n",
    "    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n",
    "                                              leaf_size=30, metric='minkowski',\n",
    "                                              p=2, metric_params=None, contamination=outlier_fraction),\n",
    "    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, max_iter=-1)\n",
    "                                         \n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest: 69\n",
      "Accuracy Score :\n",
      "0.9975773322565921\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28434\n",
      "           1       0.28      0.30      0.29        47\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.64      0.65      0.64     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Local Outlier Factor: 95\n",
      "Accuracy Score :\n",
      "0.9966644429619747\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28434\n",
      "           1       0.02      0.02      0.02        47\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.51      0.51      0.51     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Support Vector Machine: 8411\n",
      "Accuracy Score :\n",
      "0.7046803131912504\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83     28434\n",
      "           1       0.00      0.34      0.00        47\n",
      "\n",
      "    accuracy                           0.70     28481\n",
      "   macro avg       0.50      0.52      0.42     28481\n",
      "weighted avg       1.00      0.70      0.83     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "\n",
    "n_outliers = len(Fraud)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        y_pred = clf.fit_predict(X)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        clf.fit(X)\n",
    "        y_pred = clf.predict(X)\n",
    "    else:    \n",
    "        clf.fit(X)\n",
    "        scores_prediction = clf.decision_function(X)\n",
    "        y_pred = clf.predict(X)\n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVATIONS \n",
    "\n",
    "\n",
    "\n",
    "* Isolation Forest detected 69 errors versus Local Outlier Factor detecting 93 errors vs. SVM detecting 8411 errors\n",
    "\n",
    "* Isolation Forest has a 99.75% more accurate than LOF of 99.67% and SVM of 70.46\n",
    "\n",
    "* When comparing error precision & recall for 3 models , the Isolation Forest performed much better than the LOF as we can see that the detection of fraud cases is around 27 % versus LOF detection rate of just 2 % and SVM of 0\n",
    "\n",
    "* So overall Isolation Forest Method performed much better in determining the fraud cases which is around 30%.\n",
    "\n",
    "* We can also improve on this accuracy by increasing the sample size or use deep learning algorithms however at the cost of computational expense.We can also use complex anomaly detection models to get better accuracy in determining more fraudulent cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
